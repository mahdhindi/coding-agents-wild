{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADFoS6X5RXb4",
        "outputId": "dde226e2-c7f7-4926-dbae-f9a91632f1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "AIDev-pop (>=500 stars) ‚Äì Reviews & Task Type Join\n",
            "Dataset: https://huggingface.co/datasets/hao-li/AIDev\n",
            "======================================================================\n",
            "\n",
            "üì¶ Installing required packages (huggingface_hub, fsspec[http], pyarrow)...\n",
            "‚úÖ Packages installed\n",
            "\n",
            "üì• Loading PR CSV: aidev_pop_ge500_agent_prs.csv\n",
            "   ‚úÖ Loaded 12,433 PR rows, 22 columns\n",
            "   üìä Unique PR IDs in CSV: 12,433\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Loading pr_review_comments_v2, pr_reviews, pr_task_type\n",
            "======================================================================\n",
            "üì• Loading inline review comments from: hf://datasets/hao-li/AIDev/pr_review_comments_v2.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ pr_review_comments_v2: 26,868 rows, 15 columns\n",
            "üì• Loading review metadata from: hf://datasets/hao-li/AIDev/pr_reviews.parquet\n",
            "   ‚úÖ pr_reviews: 28,875 rows, 7 columns\n",
            "üì• Loading task types from: hf://datasets/hao-li/AIDev/pr_task_type.parquet\n",
            "   ‚úÖ pr_task_type: 33,596 rows, 6 columns\n",
            "\n",
            "======================================================================\n",
            "STEP 3: Linking inline comments to PR ids\n",
            "======================================================================\n",
            "‚ÑπÔ∏è No 'pr_id' in pr_review_comments_v2 ‚Äì resolving via pr_reviews...\n",
            "üìä Inline comments total: 26,868\n",
            "üìä Inline comments for 500+ stars PRs: 18,383\n",
            "\n",
            "======================================================================\n",
            "STEP 4: Joining task type classifications\n",
            "======================================================================\n",
            "üìä Task type rows for our PRs: 12,367\n",
            "\n",
            "======================================================================\n",
            "STEP 5: Building final comment-level dataset\n",
            "======================================================================\n",
            "‚úÖ Final rows (one per inline comment): 18,383\n",
            "   Columns: 40\n",
            "\n",
            "======================================================================\n",
            "STEP 6: Saving and downloading CSV\n",
            "======================================================================\n",
            "‚úÖ Saved: aidev_pop_ge500_pr_review_comments_with_task_type.csv\n",
            "   Size: 85.14 MB\n",
            "\n",
            "üöÄ Initiating file download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43e688d2-88eb-483d-a687-2345d09a52fd\", \"aidev_pop_ge500_pr_review_comments_with_task_type.csv\", 89277599)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ File download triggered\n",
            "\n",
            "======================================================================\n",
            "‚úÖ DONE ‚Äì You now have all inline review comments for your 500+ star PRs,\n",
            "   enriched with PR metadata and task_type.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Enrich 500+ stars PRs with inline review comments and task types\n",
        "# - Input: aidev_pop_ge500_agent_prs.csv  (the existing PR-level file)\n",
        "# - Extra tables: pr_review_comments_v2.parquet, pr_reviews.parquet, pr_task_type.parquet\n",
        "# - Output: aidev_pop_ge500_pr_review_comments_with_task_type.csv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"AIDev-pop (>=500 stars) ‚Äì Reviews & Task Type Join\")\n",
        "print(\"Dataset: https://huggingface.co/datasets/hao-li/AIDev\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 0: Install dependencies for hf:// parquet access (Colab-friendly)\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\nüì¶ Installing required packages (huggingface_hub, fsspec[http], pyarrow)...\")\n",
        "!pip install -q \"huggingface_hub>=0.23.0\" \"fsspec[http]\" pyarrow\n",
        "print(\"‚úÖ Packages installed\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 1: Load your 500+ stars PRs CSV\n",
        "# ---------------------------------------------------------------------\n",
        "input_pr_csv = \"aidev_pop_ge500_agent_prs.csv\"\n",
        "\n",
        "if not os.path.exists(input_pr_csv):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {input_pr_csv}. \"\n",
        "        \"Make sure it's uploaded to the Colab working directory.\"\n",
        "    )\n",
        "\n",
        "print(f\"\\nüì• Loading PR CSV: {input_pr_csv}\")\n",
        "agent_prs_pop = pd.read_csv(input_pr_csv)\n",
        "print(f\"   ‚úÖ Loaded {len(agent_prs_pop):,} PR rows, {len(agent_prs_pop.columns)} columns\")\n",
        "\n",
        "if \"id\" not in agent_prs_pop.columns:\n",
        "    raise ValueError(\"Expected a PR identifier column named 'id' in the PR CSV.\")\n",
        "\n",
        "# Normalize PR IDs to int64 where possible\n",
        "agent_prs_pop[\"id\"] = pd.to_numeric(agent_prs_pop[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "target_pr_ids = set(agent_prs_pop[\"id\"].dropna().astype(\"int64\"))\n",
        "\n",
        "print(f\"   üìä Unique PR IDs in CSV: {len(target_pr_ids):,}\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 2: Load AIDev-pop tables from Hugging Face via hf:// URLs\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 2: Loading pr_review_comments_v2, pr_reviews, pr_task_type\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "pr_review_comments_v2_path = \"hf://datasets/hao-li/AIDev/pr_review_comments_v2.parquet\"\n",
        "pr_reviews_path            = \"hf://datasets/hao-li/AIDev/pr_reviews.parquet\"\n",
        "pr_task_type_path          = \"hf://datasets/hao-li/AIDev/pr_task_type.parquet\"\n",
        "\n",
        "print(f\"üì• Loading inline review comments from: {pr_review_comments_v2_path}\")\n",
        "inline_all = pd.read_parquet(pr_review_comments_v2_path)\n",
        "print(f\"   ‚úÖ pr_review_comments_v2: {len(inline_all):,} rows, {len(inline_all.columns)} columns\")\n",
        "\n",
        "print(f\"üì• Loading review metadata from: {pr_reviews_path}\")\n",
        "pr_reviews = pd.read_parquet(pr_reviews_path)\n",
        "print(f\"   ‚úÖ pr_reviews: {len(pr_reviews):,} rows, {len(pr_reviews.columns)} columns\")\n",
        "\n",
        "print(f\"üì• Loading task types from: {pr_task_type_path}\")\n",
        "pr_task_type = pd.read_parquet(pr_task_type_path)\n",
        "print(f\"   ‚úÖ pr_task_type: {len(pr_task_type):,} rows, {len(pr_task_type.columns)} columns\")\n",
        "\n",
        "# Make sure PR ids are int64 consistently\n",
        "if \"pr_id\" in pr_reviews.columns:\n",
        "    pr_reviews[\"pr_id\"] = pd.to_numeric(pr_reviews[\"pr_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "if \"id\" in pr_task_type.columns:\n",
        "    pr_task_type[\"id\"] = pd.to_numeric(pr_task_type[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 3: Attach pr_id to inline comments (if needed) and filter to our PRs\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: Linking inline comments to PR ids\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try to normalize any pr_id column present in v2\n",
        "if \"pr_id\" in inline_all.columns:\n",
        "    inline_all[\"pr_id\"] = pd.to_numeric(inline_all[\"pr_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "if \"pr_id\" in inline_all.columns:\n",
        "    # Easiest case: v2 already carries pr_id\n",
        "    print(\"‚úÖ Detected 'pr_id' in pr_review_comments_v2 ‚Äì using direct filter\")\n",
        "    inline_filtered = inline_all[inline_all[\"pr_id\"].isin(target_pr_ids)].copy()\n",
        "else:\n",
        "    # Fallback: join through pr_reviews using pull_request_review_id -> id -> pr_id\n",
        "    if \"pull_request_review_id\" not in inline_all.columns:\n",
        "        raise ValueError(\n",
        "            \"pr_review_comments_v2 has no 'pr_id' or 'pull_request_review_id' column ‚Äì \"\n",
        "            \"cannot link to PRs.\"\n",
        "        )\n",
        "    if \"id\" not in pr_reviews.columns or \"pr_id\" not in pr_reviews.columns:\n",
        "        raise ValueError(\n",
        "            \"pr_reviews must contain 'id' and 'pr_id' to resolve comments to PRs.\"\n",
        "        )\n",
        "\n",
        "    print(\"‚ÑπÔ∏è No 'pr_id' in pr_review_comments_v2 ‚Äì resolving via pr_reviews...\")\n",
        "\n",
        "    # Join inline comments with pr_reviews to get pr_id\n",
        "    inline_with_pr = inline_all.merge(\n",
        "        pr_reviews[[\"id\", \"pr_id\"]],\n",
        "        left_on=\"pull_request_review_id\",\n",
        "        right_on=\"id\",\n",
        "        how=\"left\",\n",
        "        suffixes=(\"\", \"_review\")\n",
        "    )\n",
        "\n",
        "    inline_with_pr[\"pr_id\"] = pd.to_numeric(inline_with_pr[\"pr_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    inline_filtered = inline_with_pr[inline_with_pr[\"pr_id\"].isin(target_pr_ids)].copy()\n",
        "\n",
        "print(f\"üìä Inline comments total: {len(inline_all):,}\")\n",
        "print(f\"üìä Inline comments for 500+ stars PRs: {len(inline_filtered):,}\")\n",
        "\n",
        "if inline_filtered.empty:\n",
        "    print(\"‚ö†Ô∏è No inline comments found for the selected PRs ‚Äì result will be empty.\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 4: Attach task type to PR ids\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 4: Joining task type classifications\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "expected_task_cols = {\"agent\", \"id\", \"title\", \"reason\", \"type\"}\n",
        "missing_task_cols = expected_task_cols - set(pr_task_type.columns)\n",
        "if missing_task_cols:\n",
        "    print(f\"‚ö†Ô∏è pr_task_type is missing columns {missing_task_cols}, \"\n",
        "          \"but we'll still use 'id' and 'type' if present.\")\n",
        "\n",
        "# We just need (id, type) ‚Üí (pr_id, task_type)\n",
        "task_subset = pr_task_type.copy()\n",
        "task_subset[\"id\"] = pd.to_numeric(task_subset[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "task_subset = task_subset[task_subset[\"id\"].isin(target_pr_ids)]\n",
        "task_subset = task_subset[[\"id\", \"type\"]].rename(columns={\"id\": \"pr_id\", \"type\": \"task_type\"})\n",
        "\n",
        "print(f\"üìä Task type rows for our PRs: {len(task_subset):,}\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 5: Merge everything into a comment-level dataset\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 5: Building final comment-level dataset\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Merge inline comments with task_type (on pr_id)\n",
        "comments_with_task = inline_filtered.merge(\n",
        "    task_subset,\n",
        "    on=\"pr_id\",\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "# Merge in PR metadata from your CSV (agent_prs_pop)\n",
        "# Note: agent_prs_pop.id is the PR id, matching pr_id\n",
        "comments_full = comments_with_task.merge(\n",
        "    agent_prs_pop,\n",
        "    left_on=\"pr_id\",\n",
        "    right_on=\"id\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"_comment\", \"_pr\")\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Final rows (one per inline comment): {len(comments_full):,}\")\n",
        "print(f\"   Columns: {len(comments_full.columns)}\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Step 6: Save to CSV and download\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 6: Saving and downloading CSV\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "output_csv = \"aidev_pop_ge500_pr_review_comments_with_task_type.csv\"\n",
        "comments_full.to_csv(output_csv, index=False)\n",
        "\n",
        "size_mb = os.path.getsize(output_csv) / (1024 * 1024)\n",
        "print(f\"‚úÖ Saved: {output_csv}\")\n",
        "print(f\"   Size: {size_mb:.2f} MB\")\n",
        "\n",
        "# Optional: trigger download in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüöÄ Initiating file download...\")\n",
        "    files.download(output_csv)\n",
        "    print(\"‚úÖ File download triggered\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è Could not auto-download (likely not in Colab): {e}\")\n",
        "    print(\"   You can download the file manually from the working directory.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ DONE ‚Äì You now have all inline review comments for your 500+ star PRs,\")\n",
        "print(\"   enriched with PR metadata and task_type.\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ]
}